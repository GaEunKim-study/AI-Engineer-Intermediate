# -*- coding: utf-8 -*-
"""이미지분류신경망.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KFXlpbzzPFUnwvxjTknd_DTSOJsf_pvw

# LeNet-5

손글씨 숫자 인식 딥러닝   
합성곱과 다운 샘플링(풀링) 반복+ fc
"""

#런타임 끊어짐 방지

"""function ClickConnect(){
    console.log("코랩 연결 끊김 방지");
    document.querySelector("colab-toolbar-button#connect").click()
}
setInterval(ClickConnect, 60 * 1000)
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader,Dataset
import torchvision
from torchvision import transforms
from torch.autograd import Variable
from torch import optim
import os
import numpy as np
from PIL import Image
import cv2
import random

device=torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

"""tqdm: 진행상태를 바 형태로 가시화해서 보여주는 라이브러리"""

!pip install --user tqdm

from tqdm import tqdm_notebook as tqdm

"""데이터셋 불러오기 & 전처리 class


"""

class ImageTransform():
  def __init__(self,resize,mean,std):
    self.data_transform={
        'train': transforms.Compose([
            transforms.RandomResizedCrop(resize,scale=(0.5,1)),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(mean,std)
        ]),
        'val':transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(resize),
            transforms.ToTensor(),
            transforms.Normalize(mean,std)
        ])                    
    }
  def __call__(self,img,phase):
    return self.data_transform[phase](img)

"""transforms.**RandomResizedCrop**(resize,scale) : 입력 이미지를 주어진 크기(resize)로 조정함. 원래 이미지를 임의의 크기(scale)만큼 면적 무작위 자름  
transforms.**RandomHorizontalFlip**() : 주어진 확률로 이미지를 수평 반전시킴. (기본값 0.5)  
transforms.**ToTensor**() : PIL로 이미지를 읽으면 범위 (0,255),(H,W,C)인데 totensor사용해서 범위 (0,1)(C,H,W)로 변환  
transforms.**Normalize**(mean,std) : RGB때문에 3차원.  
-openCV를 이용해서 이미지 읽으면 RGB가 아닌 BRG 주의.  
  
__call__함수는 클래스 호출하는 클래스, 클래스를 호출하면 call의 return값이 반환됨.

"""

# Commented out IPython magic to ensure Python compatibility.
!mkdir CNN
!ls
# %cd CNN

import zipfile

# kaggle 데이터셋 다운로드
!wget --no-check-certificate \
    "https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip" \
    -O "dataset/cats-and-dogs.zip"

local_zip = 'dataset/cats-and-dogs.zip'

#zip_ref   = zipfile.ZipFile(local_zip, 'r')

!wget --no-check-certificate \
https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \
-O dataset/cats_and_dogs_filtered.zip

!unzip /content/CNN/dataset/cats_and_dogs_filtered.zip

# 폴더 만들어주기
!mkdir dataset
!mkdir dataset/cat
!mkdir dataset/dog
import os
import shutil
# train 폴더 내의 파일리스트 만들기
train_list = list(os.listdir('/content/CNN/cats_and_dogs_filtered/train'))
# 파일리스트 내의 파일을 대상으로 파일명에 따라 파일 옮겨주기
for img in train_list:
    if 'cat' in img:
        shutil.move ('cats_and_dogs_filtered/train/'+img,'dataset/cat/'+img)
    elif 'dog' in img:
        shutil.move ('cats_and_dogs_filtered/train/'+img,'dataset/dog/'+img)

cat_directory=r"/content/CNN/dataset/cat/cats/"
dog_directory=r"/content/CNN/dataset/dog/dogs/"

cat_image_filepath=sorted([os.path.join(cat_directory,f) for f in os.listdir(cat_directory)])
dog_image_filepath=sorted([os.path.join(dog_directory,f) for f in os.listdir(dog_directory)])

image_filepath=[*cat_image_filepath,*dog_image_filepath]
correct_image_filepath=[i for i in image_filepath if cv2.imread(i) is not None]
random.seed(42)
random.shuffle(correct_image_filepath)
train_image=correct_image_filepath[:1800]
val_image=correct_image_filepath[1800:1990]
test_image=correct_image_filepath[1990:2000]
print(len(train_image),len(val_image),len(test_image))

"""데이터셋 보여주는 *클래스*"""

#데이터셋 보여주기
def display_image_grid(image_filepath,predicted_labels=(),cols=5):
  rows=len(image_filepath)//cols
  figure,ax=plt.subplots(nrows=rows,ncols=cols,figsize=(12,6))
  for i, image_filepath in enumerate(image_filepath):
    image=cv2.imread(image_filepath)
    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
    true_label=os.path.normpath(image_filepath).split(os.sep)[-2]
    predicted_label=predicted_labels[i] if predicted_labels else true_label
    color="green" if true_label ==predicted_label else "red"
    ax.ravel()[i].imshow(image)
    ax.ravel()[i].set_title(predicted_label,color=color)
    ax.ravel()[i].set_axis_off()
  plt.tight_layout()
  plt.show()

display_image_grid(test_image)

"""데이터셋 불러오는 클래스"""

class DogvsCat(Dataset):
  def __init__(self,file_list,transform=None,phase="train"):
    self.file_list=file_list
    self.transform=transform
    self.phase=phase
  def __len__(self):
    return len(self.file_list)
  def __getitem__(self,idx):
    img_path=self.file_list[idx]
    img= Image.open(img_path)
    img_transed=self.transform(img,self.phase)
    label=img_path.split('/')[-1].split('.')[0]
    if label=='dog':
      label=1
    elif label=='cat':
      label=0
    return img_transed,label

"""본격 모델 구현"""

#변수설정
size=224
mean=(0.485,0.456,0.406)
std=(0.229,0.224,0.225)
batch_size=32

#데이터셋 정의
train_dataset=DogvsCat(train_image,transform=ImageTransform(size,mean,std),phase='train')
val_dataset=DogvsCat(val_image,transform=ImageTransform(size,mean,std),phase='val')
index=0
print(train_dataset.__getitem__(index)[0].size()) #훈련데이터 사이즈출력
print(train_dataset.__getitem__(index)[1]) #훈련데이터 label출력

#데이터로더 정의
train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)
val_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=False)
dataloader_dict={"train":train_loader,"val":val_loader}
batch_iterator=iter(train_loader)
inputs,label=next(batch_iterator)
print(inputs.size())
print(label)

"""cnn1: 이미지 입력은(3,224,224) 출력크기 구하는 공식=(입력데이터크기-kernel_size+2padding_size)/stride  +1
224-5+1=220
따라서 16X220X220  
maxpool1: 220/2=110  
따라서 maxpool출력크기 16X110X110  
cnn2=110-5+1=106  
cnn2출력크기 32X106X106  
maxpool2=32X53X53 
fc1=53->1  



"""

class LeNet(nn.Module):
  def __init__(self):
    super(LeNet,self).__init__()
    self.conv1=nn.Conv2d(in_channels=3,out_channels=16,kernel_size=5,stride=1,padding=0)
    self.relu1=nn.ReLU()
    self.maxpool1=nn.MaxPool2d(kernel_size=2,stride=2)
    self.conv2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1,padding=0)
    self.relu2=nn.ReLU()
    self.maxpool2=nn.MaxPool2d(kernel_size=2,stride=2)
    self.fc1=nn.Linear(32*53*53,512)
    self.relu5=nn.ReLU()
    self.fc2=nn.Linear(512,2) #2는 class수
    self.output=nn.Softmax(dim=1) #확률더높은거 하나 택


  def forward(self,x):
    out=self.conv1(x)
    out=self.relu1(out)
    out=self.maxpool1(out)
    out=self.conv2(out)
    out=self.relu2(out)
    out=self.maxpool2(out)
    out=out.view(out.size(0),-1)
    out=self.fc1(out)
    out=self.fc2(out)
    out=self.output(out)
    return out

model=LeNet()
print(model)

!pip install torchsummary

from torchsummary import summary
summary(model,input_size=(3,224,224))

#손실함수정의, optim정의
criterion=nn.CrossEntropyLoss()
optim=optim.SGD(model.parameters(),lr=0.001,momentum=0.9)
model=model.to(device)
criterion=criterion.to(device)

#학습 정의
def train_model(model,criterion,dataloader_dict,optim,num_epoch):
  since=time.time()
  best_acc=0
  for epoch in range(num_epoch):
    print('Epoch {}/{}'.format(epoch+1,num_epoch))
    print('-'*20)
    for phase in {'train','val'}:
      if phase=='train':
        model.train()
      else:
        model.eval()
      epoch_loss=0.0
      epoch_correct=0
      for inputs,labels in tqdm(dataloader_dict[phase]):
        inputs=inputs.to(device)
        labels=labels.to(device)
        optim.zero_grad()
        with torch.set_grad_enabled(phase=='train'):
          outputs=model(inputs)
          _,preds=torch.max(outputs,1)
          loss=criterion(outputs,labels)
          if phase=="train":
            loss.backward()
            optim.step()
          epoch_loss+=loss.item()*inputs.size(0)
          epoch_correct+=torch.sum(preds==labels.data)

      epoch_loss=epoch_loss/len(dataloader_dict[phase].dataset)
      epoch_acc=epoch_correct.double()/len(dataloader_dict[phase].dataset)
      print("{}, Loss: {:.4f},acc: {:.4f}".format(phase,epoch_loss,epoch_acc))
      if phase=="val"and epoch_acc>best_acc:
        best_acc=epoch_acc
        best_model_wts=model.state_dict()
    time_elapsed=time.time()-since
    print("끝나는시간 {:.0f}m,{:.0f}s".format(time_elapsed//60,time_elapsed%60))
    print("best vall acc{:.4f}".format(best_acc))
    return model

import time
num_epoch=10
model=train_model(model,criterion,dataloader_dict,optim,num_epoch)

#모델 테스트
import pandas