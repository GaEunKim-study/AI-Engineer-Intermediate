# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OV9uIXQLWg9n5Fcf_mujMG3EMauq_1ZB
"""

from torchvision import datasets
from torchvision.transforms import transforms
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

batch_size = 256
learning_rate = 0.0002
num_epoch = 10

#dataset 불러오기]
train_dataset= datasets.MNIST('./',train=True,transform=transforms.ToTensor(),target_transform=None,download=True)
test_dataset = datasets.MNIST("./", train=False, transform = transforms.ToTensor(), target_transform=None, download = True)

#load로 변환
train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=2,drop_last=True)
test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=2,drop_last=True)
"""
num_workers : 데이터를 묶을때 사용하는 프로세스 갯수
drop_last : 묶고 남은 자투리 데이터들은 버릴지 말지 
"""

#모델 설계

class CNN(nn.Module):
  def __init__(self):
    super(CNN,self).__init__() #Super class로 지금 작성하고있는 클래스 자체를 초기화하기 위함
    self.layer=nn.Sequential(
        # [256,1,28,28] -> [256,16,24,24]
        nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5),
        nn.ReLU(),    
        # [256,16,24,24] -> [256,32,20,20]
        nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5),
        nn.ReLU(), 
        # [256,32,20,20] -> [256,32,10,10]
        nn.MaxPool2d(kernel_size=2,stride=2), 
        # [256,32,10,10] -> [256,64,6,6]
        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),
        nn.ReLU(),
        # [256,64,6,6] -> [256,64,3,3]
        nn.MaxPool2d(kernel_size=2,stride=2)  
    ) # layer 결과물 : [batch_size,64,3,3]
    self.fc=nn.Sequential(
        # [256,64*3*3] -> [256,100]
        nn.Linear(64*3*3,100),                                              
        nn.ReLU(),
        # [256,100] -> [100,10]
        nn.Linear(100,10)
    )
  def forward(self,x):
    out=self.layer(x)
    out=out.view(batch_size,-1)
    out=self.fc(out)
    return out

"""layer
        #Conv2d : Convolution Filtering이라는 Signal Processing적인 방법으로 이미지를 처리 하는것으로,
        #nn.Conv2d(1,16,5)는 1개필터짜리 입력(28x28 해상도의 이미지, default filter 갯수 = 1)을 받아 16개의 필터로 size 5의 Kernel(Filtering)을 하는것입니다.
        #기본적으로 CNN은 신호/영상처리에 대한 기본적인 이해가 있어야합니다.
        #Kernel size가 5인경우, Convoltuion을 하게 되면 4개의 pixel이 사라지게 되어(28x28)의 input 이미지가 (24x24)가 됩니다.
        #이런식으로 이미지의 사이즈를 줄여가며 강한 특징만을 추려나가는게 CNN입니다.
        #MaxPooling을 중간중간 섞어줌으로써, Convolution보다 더욱 강하게 Feature들을 뽑아내줍니다.

fc
"""

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

model = CNN().to(device)
loss_f=nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)

loss_arr=[]
for i in range(num_epoch):
  for j,[image,label] in enumerate(train_loader):
    x=image.to(device)
    y=label.to(device)
    optimizer.zero_grad()
    output=model.forward(x)
    loss=loss_f(output,y)
    optimizer.step()
    if j%1000==0:
      print(loss)
      loss_arr.append(loss.cpu().detach().numpy())



